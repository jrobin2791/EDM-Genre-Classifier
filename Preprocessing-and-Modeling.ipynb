{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook is dedicated to training, testing, and validating various preprocessing and modeling methods. The goal is to attempt to formulate the best possible model for classifying the genre of an EDM song."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Don't display warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading In The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "songs = pd.read_csv('data/songs_clean.csv')\n",
    "val = pd.read_csv('data/val_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Features And Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features and target for modeling\n",
    "X = songs.drop('genre', axis=1)\n",
    "y = songs['genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the modeling data into 85% training and 15% testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.15, random_state=72, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several options for preprocessing will be compared when testing subsequent models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the models with more complex interaction columns and polynomial features will improve the accuracy of the results. However, given the size of the dataset, any more than 5 degrees can start to create problems since the number of features will be too large in comparison to the number of of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create polynomial features up to 5 degrees\n",
    "pf = PolynomialFeatures(degree=5)\n",
    "# Training data\n",
    "X_train = pf.fit_transform(X_train)\n",
    "# Test data\n",
    "X_test = pf.transform(X_test)\n",
    "# Validation data\n",
    "X_val = pf.transform(val.drop('genre', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store all the new polynomial feature names\n",
    "poly_feat = pf.get_feature_names(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the type of model, standardizing or using a power transformer to scale the variables may improve the performance of the algorithm. Both a standard scaler and a power transformer are set up here so that they can be compared with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the data through a standard scaler\n",
    "ss = StandardScaler()\n",
    "# Training data\n",
    "X_tr_sc = ss.fit_transform(X_train)\n",
    "# Test data\n",
    "X_te_sc = ss.transform(X_test)\n",
    "# Validation data\n",
    "X_val_sc = ss.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the data through a power transformer\n",
    "pt = PowerTransformer()\n",
    "# Training data\n",
    "X_tr_pt = pt.fit_transform(X_train)\n",
    "# Test data\n",
    "X_te_pt = pt.transform(X_test)\n",
    "# Validation data\n",
    "X_val_pt = pt.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A series of baseline modeling tactics will be deployed with scaled, unscaled and power transformed data. This will give a general idea of which preprocessing method works the best and which models show the most potential and should be further tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.37481525273425953\n",
      "Test Score: 0.35845896147403683\n",
      "Validation Score: 0.28\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression baseline model\n",
    "lr = LogisticRegression(random_state=72)\n",
    "lr.fit(X_train, y_train)\n",
    "print(f\"Training Score: {lr.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: {lr.score(X_test, y_test)}\")\n",
    "print(f\"Validation Score: {lr.score(X_val, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7360331067100206\n",
      "Test Score: 0.6834170854271356\n",
      "Validation Score: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression baseline model with standard scaler\n",
    "lr.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {lr.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {lr.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {lr.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7375110848359444\n",
      "Test Score: 0.6666666666666666\n",
      "Validation Score: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression baseline model with power transformer\n",
    "lr.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {lr.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {lr.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {lr.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.5900088678687555\n",
      "Test Score: 0.37018425460636517\n",
      "Validation Score: 0.33\n"
     ]
    }
   ],
   "source": [
    "# KNN baseline model\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "print(f\"Training Score: {knn.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: {knn.score(X_test, y_test)}\")\n",
    "print(f\"Validation Score: {knn.score(X_val, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7783032811114395\n",
      "Test Score: 0.6515912897822446\n",
      "Validation Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "# KNN baseline model with standard scaler\n",
    "knn.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {knn.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {knn.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {knn.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7821460242388413\n",
      "Test Score: 0.661641541038526\n",
      "Validation Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "# KNN baseline model with power transformer\n",
    "knn.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {knn.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {knn.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {knn.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9234407330771505\n",
      "Test Score: 0.6197654941373534\n",
      "Validation Score: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Decision tree baseline model\n",
    "dt = DecisionTreeClassifier(random_state=72)\n",
    "dt.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {dt.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {dt.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {dt.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9234407330771505\n",
      "Test Score: 0.6197654941373534\n",
      "Validation Score: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Decision tree baseline model with standard scaler\n",
    "dt.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {dt.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {dt.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {dt.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9234407330771505\n",
      "Test Score: 0.6164154103852596\n",
      "Validation Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Decision tree baseline model with power transformer\n",
    "dt.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {dt.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {dt.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {dt.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9154596511971623\n",
      "Test Score: 0.7035175879396985\n",
      "Validation Score: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Bagging baseline model\n",
    "bag = BaggingClassifier(random_state=72)\n",
    "bag.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {bag.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {bag.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {bag.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9154596511971623\n",
      "Test Score: 0.7035175879396985\n",
      "Validation Score: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Bagging baseline model with standard scaler\n",
    "bag.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {bag.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {bag.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {bag.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9160508424475318\n",
      "Test Score: 0.7035175879396985\n",
      "Validation Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Bagging baseline model with power transformer\n",
    "bag.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {bag.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {bag.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {bag.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9160508424475318\n",
      "Test Score: 0.6968174204355109\n",
      "Validation Score: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Random forest baseline model\n",
    "rf = RandomForestClassifier(random_state=72)\n",
    "rf.fit(X_train, y_train)\n",
    "print(f\"Training Score: {rf.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: {rf.score(X_test, y_test)}\")\n",
    "print(f\"Validation Score: {rf.score(X_val, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9160508424475318\n",
      "Test Score: 0.6968174204355109\n",
      "Validation Score: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Random forest baseline model with standard scaler\n",
    "rf.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {rf.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {rf.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {rf.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.914572864321608\n",
      "Test Score: 0.6901172529313233\n",
      "Validation Score: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Random forest baseline model with power transformer\n",
    "rf.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {rf.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {rf.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {rf.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7652970736033107\n",
      "Test Score: 0.7169179229480737\n",
      "Validation Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Adaboost baseline model\n",
    "ada = AdaBoostClassifier(random_state=72)\n",
    "ada.fit(X_train, y_train)\n",
    "print(f\"Training Score: {ada.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: {ada.score(X_test, y_test)}\")\n",
    "print(f\"Validation Score: {ada.score(X_val, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7652970736033107\n",
      "Test Score: 0.7169179229480737\n",
      "Validation Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Adaboost baseline model with standard scaler\n",
    "ada.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {ada.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {ada.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {ada.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7611587348507242\n",
      "Test Score: 0.7386934673366834\n",
      "Validation Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Adaboost forest baseline model with power transformer\n",
    "ada.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {ada.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {ada.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {ada.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8604788649127993\n",
      "Test Score: 0.7420435510887772\n",
      "Validation Score: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boost baseline model\n",
    "gb = GradientBoostingClassifier(random_state=72)\n",
    "gb.fit(X_train, y_train)\n",
    "print(f\"Training Score: {gb.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: {gb.score(X_test, y_test)}\")\n",
    "print(f\"Validation Score: {gb.score(X_val, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8604788649127993\n",
      "Test Score: 0.7420435510887772\n",
      "Validation Score: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boost baseline model with standard scaler\n",
    "gb.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {gb.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {gb.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {gb.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.857227313035767\n",
      "Test Score: 0.7353433835845896\n",
      "Validation Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boost forest baseline model with power transformer\n",
    "gb.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {gb.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {gb.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {gb.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8294413242684008\n",
      "Test Score: 0.7487437185929648\n",
      "Validation Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "# XGBoost baseline model\n",
    "xgb = XGBClassifier(random_state=72)\n",
    "xgb.fit(X_train, y_train)\n",
    "print(f\"Training Score: {xgb.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: {xgb.score(X_test, y_test)}\")\n",
    "print(f\"Validation Score: {xgb.score(X_val, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8294413242684008\n",
      "Test Score: 0.7487437185929648\n",
      "Validation Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "# XGBoost baseline model with standard scaler\n",
    "xgb.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {xgb.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {xgb.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {xgb.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8323972805202483\n",
      "Test Score: 0.7403685092127303\n",
      "Validation Score: 0.9\n"
     ]
    }
   ],
   "source": [
    "# XGBoost baseline model with power transformer\n",
    "xgb.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {xgb.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {xgb.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {xgb.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results above, it appears that the models perform best overall when the data is run through a power transformer. The logistic regression and k-nearest neighbor algorithms seem to perform significantly worse than the others overall. The next step will be to focus on improving the remaining six algorithms with parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for a randomized search over a decision tree\n",
    "params = {\n",
    "    'max_depth': range(1,25),\n",
    "    'min_samples_split': range(2,25),\n",
    "    'min_samples_leaf': range(1,25),\n",
    "    'min_weight_fraction_leaf': np.linspace(0,.5,100),\n",
    "    'max_features': np.linspace(.001,1.0,100),\n",
    "    'max_leaf_nodes': range(2,100),\n",
    "    'min_impurity_decrease': np.linspace(0,1,100),\n",
    "    'presort': range(2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=72,\n",
       "            splitter='best'),\n",
       "          fit_params=None, iid='warn', n_iter=500, n_jobs=None,\n",
       "          param_distributions={'max_depth': range(1, 25), 'min_samples_split': range(2, 25), 'min_samples_leaf': range(1, 25), 'min_weight_fraction_leaf': array([0.     , 0.00505, ..., 0.49495, 0.5    ]), 'max_features': array([0.001  , 0.01109, ..., 0.98991, 1.     ]), 'max_leaf_nodes': range(2, 100), 'min_impurity_decrease': array([0.    , 0.0101, ..., 0.9899, 1.    ]), 'presort': range(0, 2)},\n",
       "          pre_dispatch='2*n_jobs', random_state=72, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a randomized search with 3 folds\n",
    "rs = RandomizedSearchCV(dt, params, 500, cv=3, random_state=72)\n",
    "rs.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'presort': 0,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 21,\n",
       " 'min_impurity_decrease': 0.020202020202020204,\n",
       " 'max_leaf_nodes': 92,\n",
       " 'max_features': 0.5963636363636364,\n",
       " 'max_depth': 3}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7658882648536801\n",
      "Test Score: 0.7135678391959799\n",
      "Validation Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Score the best decision tree estimator on training, test, and validation\n",
    "print(f\"Training Score: {rs.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {rs.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {rs.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The randomized search over parameters resulted in a pretty decent model, significantly better than the baseline. The best parameters from this search will now be tuned further using grid search in an attempt to further improve this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for a grid search over a decision tree\n",
    "params = {\n",
    "    'min_samples_split': range(4,7),\n",
    "    'min_samples_leaf': range(20,23),\n",
    "    'min_impurity_decrease': [.01,.02,.03],\n",
    "    'max_leaf_nodes': range(91,94),\n",
    "    'max_features': [.5,.6,.7],\n",
    "    'max_depth': range(2,5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=0.5963636363636364, max_leaf_nodes=92,\n",
       "            min_impurity_decrease=0.020202020202020204,\n",
       "            min_impurity_split=None, min_samples_leaf=21,\n",
       "            min_samples_split=5, min_weight_fraction_leaf=0.0, presort=0,\n",
       "            random_state=72, splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'min_samples_split': range(4, 7), 'min_samples_leaf': range(20, 23), 'min_impurity_decrease': [0.01, 0.02, 0.03], 'max_leaf_nodes': range(91, 94), 'max_features': [0.5, 0.6, 0.7], 'max_depth': range(2, 5)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a grid search with 3 folds\n",
    "gs = GridSearchCV(rs.best_estimator_, params, cv=3)\n",
    "gs.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4,\n",
       " 'max_features': 0.5,\n",
       " 'max_leaf_nodes': 91,\n",
       " 'min_impurity_decrease': 0.01,\n",
       " 'min_samples_leaf': 20,\n",
       " 'min_samples_split': 4}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7803724504877327\n",
      "Test Score: 0.7303182579564489\n",
      "Validation Score: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Score the best decision tree estimator on training, test, and validation\n",
    "print(f\"Training Score: {gs.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {gs.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {gs.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results show significant improvement from the randomized search. Perhaps they can be improved even more with additional fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for a second grid search over a decision tree\n",
    "params = {\n",
    "    'min_samples_split': range(3,6),\n",
    "    'min_samples_leaf': range(19,22),\n",
    "    'min_impurity_decrease': [0,.01,.02],\n",
    "    'max_leaf_nodes': range(90,93),\n",
    "    'max_features': [.4,.5,.6],\n",
    "    'max_depth': range(3,6)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=0.5963636363636364, max_leaf_nodes=92,\n",
       "            min_impurity_decrease=0.020202020202020204,\n",
       "            min_impurity_split=None, min_samples_leaf=21,\n",
       "            min_samples_split=5, min_weight_fraction_leaf=0.0, presort=0,\n",
       "            random_state=72, splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'min_samples_split': range(3, 6), 'min_samples_leaf': range(19, 22), 'min_impurity_decrease': [0, 0.01, 0.02], 'max_leaf_nodes': range(90, 93), 'max_features': [0.4, 0.5, 0.6], 'max_depth': range(3, 6)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a grid search with 3 folds\n",
    "gs2 = GridSearchCV(rs.best_estimator_, params, cv=3)\n",
    "gs2.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4,\n",
       " 'max_features': 0.4,\n",
       " 'max_leaf_nodes': 90,\n",
       " 'min_impurity_decrease': 0.01,\n",
       " 'min_samples_leaf': 19,\n",
       " 'min_samples_split': 3}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "gs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7777120898610701\n",
      "Test Score: 0.7269681742043551\n",
      "Validation Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Score the best decision tree estimator on training, test, and validation\n",
    "print(f\"Training Score: {gs2.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {gs2.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {gs2.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best estimator from the previous grid search actually did better than this last one, so that is what will be saved as the final decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best estimator as the final decision tree model\n",
    "dt = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for a randomized search over a bagging classifier\n",
    "params = {\n",
    "    'n_estimators': range(1,100),\n",
    "    'max_samples': np.linspace(.001,1,100),\n",
    "    'max_features': np.linspace(.001,1,100),\n",
    "    'bootstrap': range(2),\n",
    "    'bootstrap_features': range(2),\n",
    "    'warm_start': range(2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "         n_estimators=10, n_jobs=None, oob_score=False, random_state=72,\n",
       "         verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=50, n_jobs=None,\n",
       "          param_distributions={'n_estimators': range(1, 100), 'max_samples': array([0.001  , 0.01109, ..., 0.98991, 1.     ]), 'max_features': array([0.001  , 0.01109, ..., 0.98991, 1.     ]), 'bootstrap': range(0, 2), 'bootstrap_features': range(0, 2), 'warm_start': range(0, 2)},\n",
       "          pre_dispatch='2*n_jobs', random_state=72, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a randomized search with 3 folds\n",
    "rs = RandomizedSearchCV(bag, params, 50, cv=3, random_state=72)\n",
    "rs.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'warm_start': 0,\n",
       " 'n_estimators': 96,\n",
       " 'max_samples': 0.25327272727272726,\n",
       " 'max_features': 0.4752727272727273,\n",
       " 'bootstrap_features': 1,\n",
       " 'bootstrap': 0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8486550399054094\n",
      "Test Score: 0.7453936348408711\n",
      "Validation Score: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Score the best bagging estimator on training, test, and validation\n",
    "print(f\"Training Score: {rs.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {rs.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {rs.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the best results of any model so far, and show a marked improvement from the baseline bagging model, but let's see if they can be improved further with a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for a grid search over a bagging classifier\n",
    "params = {\n",
    "    'n_estimators': range(58,63),\n",
    "    'bootstrap': range(2),\n",
    "    'bootstrap_features': range(2),\n",
    "    'warm_start': range(2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=BaggingClassifier(base_estimator=None, bootstrap=0, bootstrap_features=1,\n",
       "         max_features=0.4752727272727273, max_samples=0.25327272727272726,\n",
       "         n_estimators=96, n_jobs=None, oob_score=False, random_state=72,\n",
       "         verbose=0, warm_start=0),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': range(58, 63), 'bootstrap': range(0, 2), 'bootstrap_features': range(0, 2), 'warm_start': range(0, 2)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a grid search with 3 folds\n",
    "gs = GridSearchCV(rs.best_estimator_, params, cv=3)\n",
    "gs.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': 1, 'bootstrap_features': 0, 'n_estimators': 60, 'warm_start': 0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8424475317765298\n",
      "Test Score: 0.7437185929648241\n",
      "Validation Score: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Score the best bagging estimator on training, test, and validation\n",
    "print(f\"Training Score: {gs.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {gs.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {gs.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model's performance was slightly worse in training, testing, and validation. Therefore the original best estimator from the randomized search will be saved as the final bagging model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best estimator as the final bagging model\n",
    "bag = rs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for a randomized search over a random forest\n",
    "params = {\n",
    "    'n_estimators': range(1,200),\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'max_depth': range(1,25),\n",
    "    'min_samples_split': range(2,25),\n",
    "    'min_samples_leaf': range(1,25),\n",
    "    'min_weight_fraction_leaf': np.linspace(0,.5,100),\n",
    "    'max_features': np.linspace(.001,1.0,100),\n",
    "    'max_leaf_nodes': range(2,100),\n",
    "    'min_impurity_decrease': np.linspace(0,1,100),\n",
    "    'bootstrap': range(2),\n",
    "    'warm_start': range(2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=72, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=50, n_jobs=None,\n",
       "          param_distributions={'n_estimators': range(1, 200), 'criterion': ['gini', 'entropy'], 'max_depth': range(1, 25), 'min_samples_split': range(2, 25), 'min_samples_leaf': range(1, 25), 'min_weight_fraction_leaf': array([0.     , 0.00505, ..., 0.49495, 0.5    ]), 'max_features': array([0.001  , 0.01109, ..., 0.98991, 1.     ]), 'max_leaf_nodes': range(2, 100), 'min_impurity_decrease': array([0.    , 0.0101, ..., 0.9899, 1.    ]), 'bootstrap': range(0, 2), 'warm_start': range(0, 2)},\n",
       "          pre_dispatch='2*n_jobs', random_state=72, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a randomized search with 3 folds\n",
    "rs = RandomizedSearchCV(rf, params, 50, cv=3, random_state=72)\n",
    "rs.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'warm_start': 1,\n",
       " 'n_estimators': 125,\n",
       " 'min_weight_fraction_leaf': 0.19191919191919193,\n",
       " 'min_samples_split': 9,\n",
       " 'min_samples_leaf': 22,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'max_leaf_nodes': 26,\n",
       " 'max_features': 0.3440909090909091,\n",
       " 'max_depth': 5,\n",
       " 'criterion': 'entropy',\n",
       " 'bootstrap': 1}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7496305054685191\n",
      "Test Score: 0.7269681742043551\n",
      "Validation Score: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Score the best random forest estimator on training, test, and validation\n",
    "print(f\"Training Score: {rs.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {rs.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {rs.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other tuned models thus far have managed to get over 90% accuracy on the validation set. The training and test scores here are not significantly better than the previous models either. If this model is going to be used, it will have to be adjusted a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for a grid search over a random forest\n",
    "params = {\n",
    "    'n_estimators': [100,125,150],\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'max_depth': [4,5,6],\n",
    "    'min_samples_leaf': [20,22,24],\n",
    "    'warm_start': range(2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=1, class_weight=None, criterion='entropy',\n",
       "            max_depth=5, max_features=0.3440909090909091,\n",
       "            max_leaf_nodes=26, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=22,\n",
       "            min_samples_split=9,\n",
       "            min_weight_fraction_leaf=0.19191919191919193, n_estimators=125,\n",
       "            n_jobs=None, oob_score=False, random_state=72, verbose=0,\n",
       "            warm_start=1),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [100, 125, 150], 'criterion': ['gini', 'entropy'], 'max_depth': [4, 5, 6], 'min_samples_leaf': [20, 22, 24], 'warm_start': range(0, 2)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a grid search with 3 folds\n",
    "gs = GridSearchCV(rs.best_estimator_, params, cv=3)\n",
    "gs.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 4,\n",
       " 'min_samples_leaf': 20,\n",
       " 'n_estimators': 125,\n",
       " 'warm_start': 0}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7496305054685191\n",
      "Test Score: 0.7269681742043551\n",
      "Validation Score: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Score the best random forest estimator on training, test, and validation\n",
    "print(f\"Training Score: {gs.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {gs.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {gs.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from the grid search are exactly the same as the randomized search. Since random forest is not performing as well as the previous models, there is no need to bother with it anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for a randomized search over adaboost\n",
    "params = {\n",
    "    'learning_rate': np.linspace(.001,5,100),\n",
    "    'n_estimators': range(1,100),\n",
    "    'algorithm': ['SAMME', 'SAMME.R']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=72),\n",
       "          fit_params=None, iid='warn', n_iter=50, n_jobs=None,\n",
       "          param_distributions={'learning_rate': array([1.00000e-03, 5.14949e-02, ..., 4.94951e+00, 5.00000e+00]), 'n_estimators': range(1, 100), 'algorithm': ['SAMME', 'SAMME.R']},\n",
       "          pre_dispatch='2*n_jobs', random_state=72, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a randomized search with 3 folds\n",
    "rs = RandomizedSearchCV(ada, params, 50, cv=3, random_state=72)\n",
    "rs.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 65, 'learning_rate': 0.7584242424242423, 'algorithm': 'SAMME'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7723913686077446\n",
      "Test Score: 0.7286432160804021\n",
      "Validation Score: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Score the best adaboost estimator on training, test, and validation\n",
    "print(f\"Training Score: {rs.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {rs.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {rs.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original adaboost model actually performed much better than this one. One more attempt to do better than the original will be made with a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for a grid search over adaboost\n",
    "params = {\n",
    "    'learning_rate': [.5,.75,1],\n",
    "    'n_estimators': range(60,71),\n",
    "    'algorithm': ['SAMME', 'SAMME.R']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME', base_estimator=None,\n",
       "          learning_rate=0.7584242424242423, n_estimators=65,\n",
       "          random_state=72),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'learning_rate': [0.5, 0.75, 1], 'n_estimators': range(60, 71), 'algorithm': ['SAMME', 'SAMME.R']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a grid search with 3 folds\n",
    "gs = GridSearchCV(rs.best_estimator_, params, cv=3)\n",
    "gs.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'SAMME', 'learning_rate': 1, 'n_estimators': 68}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7650014779781259\n",
      "Test Score: 0.7252931323283082\n",
      "Validation Score: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Score the best adaboost estimator on training, test, and validation\n",
    "print(f\"Training Score: {gs.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {gs.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {gs.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are only getting worse, so the original model is the best choice for adaboost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for a randomized search over gradient boost\n",
    "params = {\n",
    "    'learning_rate': np.linspace(.001,.5,100),\n",
    "    'n_estimators': range(1,200),\n",
    "    'subsample': np.linspace(0,1,100),\n",
    "    'min_samples_split': range(2,10),\n",
    "    'min_samples_leaf': range(1,10),\n",
    "    'max_depth': range(1,50),\n",
    "    'min_impurity_decrease': np.linspace(.001,1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=5, n_jobs=None,\n",
       "          param_distributions={'learning_rate': array([0.001  , 0.00604, ..., 0.49496, 0.5    ]), 'n_estimators': range(1, 200), 'subsample': array([0.    , 0.0101, ..., 0.9899, 1.    ]), 'min_samples_split': range(2, 10), 'min_samples_leaf': range(1, 10), 'max_depth': range(1, 50), 'min_impurity_decrease': a...51, 0.8369 ,\n",
       "       0.85729, 0.87767, 0.89806, 0.91845, 0.93884, 0.95922, 0.97961,\n",
       "       1.     ])},\n",
       "          pre_dispatch='2*n_jobs', random_state=72, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a randomized search with 3 folds\n",
    "rs = RandomizedSearchCV(gb, params, 5, cv=3, random_state=72)\n",
    "rs.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.29292929292929293,\n",
       " 'n_estimators': 131,\n",
       " 'min_samples_split': 4,\n",
       " 'min_samples_leaf': 6,\n",
       " 'min_impurity_decrease': 0.18448979591836737,\n",
       " 'max_depth': 18,\n",
       " 'learning_rate': 0.046363636363636364}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9074785693171741\n",
      "Test Score: 0.7085427135678392\n",
      "Validation Score: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Score the best gradient boost estimator on training, test, and validation\n",
    "print(f\"Training Score: {rs.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {rs.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {rs.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has significantly higher variance compared to the baseline model, but it scored higher on the validation data, which is important. Let's see if a grid search will help combat some of the overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for a grid search over gradient boost\n",
    "params = {\n",
    "    'criterion': ['friedman_mse','mse','mae'],\n",
    "    'warm_start': range(2),\n",
    "    'presort': range(2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.046363636363636364, loss='deviance',\n",
       "              max_depth=18, max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.18448979591836737,\n",
       "              min_impurity_split=N...0.29292929292929293, tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'criterion': ['friedman_mse', 'mse', 'mae'], 'warm_start': range(0, 2), 'presort': range(0, 2)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a grid search with 3 folds\n",
    "gs = GridSearchCV(rs.best_estimator_, params, cv=3)\n",
    "gs.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse', 'presort': 0, 'warm_start': 0}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9071829736919894\n",
      "Test Score: 0.711892797319933\n",
      "Validation Score: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Score the best gradient boost estimator on training, test, and validation\n",
    "print(f\"Training Score: {gs.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {gs.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {gs.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is a very slight decrease in variance with this second model, there is also a decrease in the validation score, and for this reason, the best estimator from the randomized search is still preferred. It is possible that further tuning of hyperparameters will produce better results, so another grid search should be attempted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for a second grid search over gradient boost\n",
    "params = {\n",
    "    'min_weight_fraction_leaf': [0.,.25,.5],\n",
    "    'max_features': [None,'auto','log2'],\n",
    "    'max_leaf_nodes': [None,25]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.046363636363636364, loss='deviance',\n",
       "              max_depth=18, max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.18448979591836737,\n",
       "              min_impurity_split=N...0.29292929292929293, tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'min_weight_fraction_leaf': [0.0, 0.25, 0.5], 'max_features': [None, 'auto', 'log2'], 'max_leaf_nodes': [None, 25]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a grid search with 3 folds\n",
    "gs2 = GridSearchCV(rs.best_estimator_, params, cv=3)\n",
    "gs2.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_weight_fraction_leaf': 0.25}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "gs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7853975761158735\n",
      "Test Score: 0.7353433835845896\n",
      "Validation Score: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Score the best gradient boost estimator on training, test, and validation\n",
    "print(f\"Training Score: {gs2.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {gs2.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {gs2.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has accounted for most of the variance in the previous models, but the validation score took even more of a hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best estimator as the final gradient boost model\n",
    "gb = rs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for a randomized search over XGBoost\n",
    "params = {\n",
    "    'learning_rate': np.linspace(.001,.5,25),\n",
    "    'n_estimators': range(1,200),\n",
    "    'gamma': range(10),\n",
    "    'min_child_weight': range(1,10),\n",
    "    'max_delta_step': range(10),\n",
    "    'subsample': np.linspace(0,1,25),\n",
    "    'colsample_bytree': np.linspace(0,1,25),\n",
    "    'colsample_bylevel': np.linspace(0,1,25),\n",
    "    'colsample_bynode': np.linspace(0,1,25),\n",
    "    'max_depth': range(1,25),\n",
    "    'reg_alpha': range(5),\n",
    "    'reg_lambda': range(5),\n",
    "    'scale_pos_weight': np.linspace(0,1,25),\n",
    "    'base_score': np.linspace(0,1,25)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='multi:softprob', random_state=72, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "          fit_params=None, iid='warn', n_iter=50, n_jobs=None,\n",
       "          param_distributions={'learning_rate': array([0.001  , 0.02179, 0.04258, 0.06338, 0.08417, 0.10496, 0.12575,\n",
       "       0.14654, 0.16733, 0.18812, 0.20892, 0.22971, 0.2505 , 0.27129,\n",
       "       0.29208, 0.31288, 0.33367, 0.35446, 0.37525, 0.39604, 0.41683,\n",
       "       0.43762, 0.45842, 0.47921, 0.5    ]), 'n_esti..., 0.625  , 0.66667, 0.70833, 0.75   , 0.79167, 0.83333,\n",
       "       0.875  , 0.91667, 0.95833, 1.     ])},\n",
       "          pre_dispatch='2*n_jobs', random_state=72, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a randomized search with 3 folds\n",
    "rs = RandomizedSearchCV(xgb, params, 50, cv=3, random_state=72)\n",
    "rs.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.41666666666666663,\n",
       " 'scale_pos_weight': 0.4583333333333333,\n",
       " 'reg_lambda': 0,\n",
       " 'reg_alpha': 2,\n",
       " 'n_estimators': 91,\n",
       " 'min_child_weight': 9,\n",
       " 'max_depth': 15,\n",
       " 'max_delta_step': 3,\n",
       " 'learning_rate': 0.021791666666666668,\n",
       " 'gamma': 0,\n",
       " 'colsample_bytree': 0.6666666666666666,\n",
       " 'colsample_bynode': 0.3333333333333333,\n",
       " 'colsample_bylevel': 1.0,\n",
       " 'base_score': 0.08333333333333333}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8016553355010346\n",
      "Test Score: 0.7470686767169179\n",
      "Validation Score: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Score the best XGBoost estimator on training, test, and validation\n",
    "print(f\"Training Score: {rs.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {rs.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {rs.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an improvement from the original XGBoost model. Let's see if it can be get even better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for a grid search over XGBoost\n",
    "params = {\n",
    "    'booster': ['gbtree','gblinear','dart'],\n",
    "    'learning_rate': [.01,.05],\n",
    "    'n_estimators': [80,100],\n",
    "    'max_depth': [10,20],\n",
    "    'reg_alpha': range(3),\n",
    "    'reg_lambda': range(3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.08333333333333333, booster='gbtree',\n",
       "       colsample_bylevel=1.0, colsample_bynode=0.3333333333333333,\n",
       "       colsample_bytree=0.6666666666666666, gamma=0,\n",
       "       learning_rate=0.021791666666666668, max_delta_step=3, max_depth=15,\n",
       "       min_child_weight=9, miss...eight=0.4583333333333333,\n",
       "       seed=None, silent=None, subsample=0.41666666666666663, verbosity=1),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'booster': ['gbtree', 'gblinear', 'dart'], 'learning_rate': [0.01, 0.05], 'n_estimators': [80, 100], 'max_depth': [10, 20], 'reg_alpha': range(0, 3), 'reg_lambda': range(0, 3)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a grid search with 3 folds\n",
    "gs = GridSearchCV(rs.best_estimator_, params, cv=3)\n",
    "gs.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 'gbtree',\n",
       " 'learning_rate': 0.01,\n",
       " 'max_depth': 10,\n",
       " 'n_estimators': 100,\n",
       " 'reg_alpha': 1,\n",
       " 'reg_lambda': 1}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7986993792491871\n",
      "Test Score: 0.7420435510887772\n",
      "Validation Score: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Score the best XGBoost estimator on training, test, and validation\n",
    "print(f\"Training Score: {gs.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {gs.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {gs.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for a second grid search over XGBoost\n",
    "params = {\n",
    "    'learning_rate': [.01,.02],\n",
    "    'n_estimators': [90,100],\n",
    "    'max_depth': [10,15],\n",
    "    'reg_alpha': range(3),\n",
    "    'reg_lambda': range(3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.08333333333333333, booster='gbtree',\n",
       "       colsample_bylevel=1.0, colsample_bynode=0.3333333333333333,\n",
       "       colsample_bytree=0.6666666666666666, gamma=0, learning_rate=0.01,\n",
       "       max_delta_step=3, max_depth=10, min_child_weight=9, missing=None,\n",
       "       n_esti...eight=0.4583333333333333, seed=None,\n",
       "       silent=None, subsample=0.41666666666666663, verbosity=1),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'learning_rate': [0.01, 0.02], 'n_estimators': [90, 100], 'max_depth': [10, 15], 'reg_alpha': range(0, 3), 'reg_lambda': range(0, 3)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a grid search with 3 folds\n",
    "gs2 = GridSearchCV(gs.best_estimator_, params, cv=3)\n",
    "gs2.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01,\n",
       " 'max_depth': 10,\n",
       " 'n_estimators': 90,\n",
       " 'reg_alpha': 1,\n",
       " 'reg_lambda': 2}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "gs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7989949748743719\n",
      "Test Score: 0.7437185929648241\n",
      "Validation Score: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Score the best XGBoost estimator on training, test, and validation\n",
    "print(f\"Training Score: {gs2.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {gs2.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {gs2.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for a third grid search over XGBoost\n",
    "params = {\n",
    "    'learning_rate': [.005,.01],\n",
    "    'max_depth': [5,10],\n",
    "    'reg_alpha': range(3),\n",
    "    'reg_lambda': range(3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.08333333333333333, booster='gbtree',\n",
       "       colsample_bylevel=1.0, colsample_bynode=0.3333333333333333,\n",
       "       colsample_bytree=0.6666666666666666, gamma=0, learning_rate=0.01,\n",
       "       max_delta_step=3, max_depth=10, min_child_weight=9, missing=None,\n",
       "       n_esti...eight=0.4583333333333333, seed=None,\n",
       "       silent=None, subsample=0.41666666666666663, verbosity=1),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'learning_rate': [0.005, 0.01], 'max_depth': [5, 10], 'reg_alpha': range(0, 3), 'reg_lambda': range(0, 3)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a grid search with 3 folds\n",
    "gs3 = GridSearchCV(gs.best_estimator_, params, cv=3)\n",
    "gs3.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.005, 'max_depth': 5, 'reg_alpha': 0, 'reg_lambda': 0}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "gs3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7945610404966007\n",
      "Test Score: 0.7487437185929648\n",
      "Validation Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Score the best XGBoost estimator on training, test, and validation\n",
    "print(f\"Training Score: {gs3.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {gs3.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {gs3.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best estimator as the final gradient boost model\n",
    "xgb = gs2.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a list of estimators for the voting classifier\n",
    "models = [\n",
    "    ('dt', dt),\n",
    "    ('bag', bag),\n",
    "    ('ada', ada),\n",
    "    ('gb', gb),\n",
    "    ('xgb', xgb)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8226426248891516\n",
      "Test Score: 0.7453936348408711\n",
      "Validation Score: 0.93\n"
     ]
    }
   ],
   "source": [
    "vc = VotingClassifier(models)\n",
    "vc.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {vc.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {vc.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {vc.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8312148980195093\n",
      "Test Score: 0.7437185929648241\n",
      "Validation Score: 0.93\n"
     ]
    }
   ],
   "source": [
    "vc = VotingClassifier(models, 'soft')\n",
    "vc.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {vc.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {vc.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {vc.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8229382205143364\n",
      "Test Score: 0.7520938023450586\n",
      "Validation Score: 0.93\n"
     ]
    }
   ],
   "source": [
    "vc = VotingClassifier(models)\n",
    "vc.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {vc.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {vc.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {vc.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8329884717706177\n",
      "Test Score: 0.7420435510887772\n",
      "Validation Score: 0.93\n"
     ]
    }
   ],
   "source": [
    "vc = VotingClassifier(models, 'soft')\n",
    "vc.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {vc.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {vc.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {vc.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8229382205143364\n",
      "Test Score: 0.7504187604690117\n",
      "Validation Score: 0.93\n"
     ]
    }
   ],
   "source": [
    "vc = VotingClassifier(models)\n",
    "vc.fit(X_train, y_train)\n",
    "print(f\"Training Score: {vc.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: {vc.score(X_test, y_test)}\")\n",
    "print(f\"Validation Score: {vc.score(X_val, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8329884717706177\n",
      "Test Score: 0.7437185929648241\n",
      "Validation Score: 0.93\n"
     ]
    }
   ],
   "source": [
    "vc = VotingClassifier(models, 'soft')\n",
    "vc.fit(X_train, y_train)\n",
    "print(f\"Training Score: {vc.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: {vc.score(X_test, y_test)}\")\n",
    "print(f\"Validation Score: {vc.score(X_val, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist the model for the final app\n",
    "with open('final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(vc, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the top 20 most important features from XGBoost in a dataframe\n",
    "feat_imp = pd.DataFrame(xgb.feature_importances_, index=poly_feat).sort_values(0, ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the top 20 features\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.barh(feat_imp.index, feat_imp[0])\n",
    "plt.gca().invert_yaxis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
