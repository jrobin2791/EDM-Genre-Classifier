{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook is dedicated to training, testing, and validating various preprocessing and modeling methods. The goal is to attempt to formulate the best possible model for classifying the genre of an EDM song."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading In The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "songs = pd.read_csv('data/songs_clean.csv')\n",
    "val = pd.read_csv('data/val_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Features And Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features and target for modeling\n",
    "X = songs.drop('genre', axis=1)\n",
    "y = songs['genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the modeling data into 80% training and 20% testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.15, random_state=72, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several options for preprocessing will be compared when testing subsequent models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the models with more complex interaction columns and polynomial features will improve the accuracy of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create polynomial features up to 5 degrees\n",
    "pf = PolynomialFeatures(degree=5)\n",
    "# Training data\n",
    "X_train = pf.fit_transform(X_train)\n",
    "# Test data\n",
    "X_test = pf.transform(X_test)\n",
    "# Validation data\n",
    "X_val = pf.transform(val.drop('genre', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store all the new polynomial feature names\n",
    "poly_feat = pf.get_feature_names(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the type of model, standardizing or using a power transformer to scale the variables may improve the performance of the algorithm. Both a standard scaler and a power transformer are set up here so that they can be compared with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the data through a standard scaler\n",
    "ss = StandardScaler()\n",
    "# Training data\n",
    "X_tr_sc = ss.fit_transform(X_train)\n",
    "# Test data\n",
    "X_te_sc = ss.transform(X_test)\n",
    "# Validation data\n",
    "X_val_sc = ss.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuarobin/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/preprocessing/data.py:2778: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "/Users/joshuarobin/anaconda3/envs/dsi/lib/python3.6/site-packages/numpy/core/_methods.py:121: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Users/joshuarobin/anaconda3/envs/dsi/lib/python3.6/site-packages/numpy/core/_methods.py:122: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims)\n"
     ]
    }
   ],
   "source": [
    "# Run the data through a power transformer\n",
    "pt = PowerTransformer()\n",
    "# Training data\n",
    "X_tr_pt = pt.fit_transform(X_train)\n",
    "# Test data\n",
    "X_te_pt = pt.transform(X_test)\n",
    "# Validation data\n",
    "X_val_pt = pt.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A series of baseline modeling tactics will be deployed with scaled, unscaled and power transformed data. This will give a general idea of which preprocessing method works the best and which models show the most potential and should be further tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuarobin/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/joshuarobin/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.37481525273425953\n",
      "Test Score: 0.35845896147403683\n",
      "Validation Score: 0.28\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression baseline model\n",
    "lr = LogisticRegression(random_state=72)\n",
    "lr.fit(X_train, y_train)\n",
    "print(f\"Training Score: {lr.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: {lr.score(X_test, y_test)}\")\n",
    "print(f\"Validation Score: {lr.score(X_val, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuarobin/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/joshuarobin/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7360331067100206\n",
      "Test Score: 0.6834170854271356\n",
      "Validation Score: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression baseline model with standard scaler\n",
    "lr.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {lr.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {lr.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {lr.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuarobin/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/joshuarobin/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7375110848359444\n",
      "Test Score: 0.6666666666666666\n",
      "Validation Score: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression baseline model with power transformer\n",
    "lr.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {lr.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {lr.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {lr.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.5900088678687555\n",
      "Test Score: 0.37018425460636517\n",
      "Validation Score: 0.33\n"
     ]
    }
   ],
   "source": [
    "# KNN baseline model\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "print(f\"Training Score: {knn.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: {knn.score(X_test, y_test)}\")\n",
    "print(f\"Validation Score: {knn.score(X_val, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7783032811114395\n",
      "Test Score: 0.6515912897822446\n",
      "Validation Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "# KNN baseline model with standard scaler\n",
    "knn.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {knn.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {knn.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {knn.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7821460242388413\n",
      "Test Score: 0.661641541038526\n",
      "Validation Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "# KNN baseline model with power transformer\n",
    "knn.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {knn.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {knn.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {knn.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9234407330771505\n",
      "Test Score: 0.6197654941373534\n",
      "Validation Score: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Decision tree baseline model\n",
    "dt = DecisionTreeClassifier(random_state=72)\n",
    "dt.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {dt.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {dt.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {dt.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9234407330771505\n",
      "Test Score: 0.6197654941373534\n",
      "Validation Score: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Decision tree baseline model with standard scaler\n",
    "dt.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {dt.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {dt.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {dt.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9234407330771505\n",
      "Test Score: 0.6164154103852596\n",
      "Validation Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Decision tree baseline model with power transformer\n",
    "dt.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {dt.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {dt.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {dt.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9154596511971623\n",
      "Test Score: 0.7035175879396985\n",
      "Validation Score: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Bagging baseline model\n",
    "bag = BaggingClassifier(random_state=72)\n",
    "bag.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {bag.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {bag.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {bag.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9154596511971623\n",
      "Test Score: 0.7035175879396985\n",
      "Validation Score: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Bagging baseline model with standard scaler\n",
    "bag.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {bag.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {bag.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {bag.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9160508424475318\n",
      "Test Score: 0.7035175879396985\n",
      "Validation Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Bagging baseline model with power transformer\n",
    "bag.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {bag.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {bag.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {bag.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuarobin/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9160508424475318\n",
      "Test Score: 0.6968174204355109\n",
      "Validation Score: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Random forest baseline model\n",
    "rf = RandomForestClassifier(random_state=72)\n",
    "rf.fit(X_train, y_train)\n",
    "print(f\"Training Score: {rf.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: {rf.score(X_test, y_test)}\")\n",
    "print(f\"Validation Score: {rf.score(X_val, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9160508424475318\n",
      "Test Score: 0.6968174204355109\n",
      "Validation Score: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Random forest baseline model with standard scaler\n",
    "rf.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {rf.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {rf.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {rf.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.914572864321608\n",
      "Test Score: 0.6901172529313233\n",
      "Validation Score: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Random forest baseline model with power transformer\n",
    "rf.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {rf.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {rf.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {rf.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'rf__max_depth': [12,13,14],\n",
    "#     'rf__min_samples_leaf': [3,4,5],\n",
    "#     'rf__n_estimators': [50,51,52],\n",
    "#     'rf__max_features': ['auto',25,50,100]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7652970736033107\n",
      "Test Score: 0.7169179229480737\n",
      "Validation Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Adaboost baseline model\n",
    "ada = AdaBoostClassifier(random_state=72)\n",
    "ada.fit(X_train, y_train)\n",
    "print(f\"Training Score: {ada.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: {ada.score(X_test, y_test)}\")\n",
    "print(f\"Validation Score: {ada.score(X_val, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7652970736033107\n",
      "Test Score: 0.7169179229480737\n",
      "Validation Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Adaboost baseline model with standard scaler\n",
    "ada.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {ada.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {ada.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {ada.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7611587348507242\n",
      "Test Score: 0.7386934673366834\n",
      "Validation Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Adaboost forest baseline model with power transformer\n",
    "ada.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {ada.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {ada.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {ada.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8604788649127993\n",
      "Test Score: 0.7420435510887772\n",
      "Validation Score: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boost baseline model\n",
    "gb = GradientBoostingClassifier(random_state=72)\n",
    "gb.fit(X_train, y_train)\n",
    "print(f\"Training Score: {gb.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: {gb.score(X_test, y_test)}\")\n",
    "print(f\"Validation Score: {gb.score(X_val, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8604788649127993\n",
      "Test Score: 0.7420435510887772\n",
      "Validation Score: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boost baseline model with standard scaler\n",
    "gb.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {gb.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {gb.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {gb.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.857227313035767\n",
      "Test Score: 0.7353433835845896\n",
      "Validation Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boost forest baseline model with power transformer\n",
    "gb.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {gb.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {gb.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {gb.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8294413242684008\n",
      "Test Score: 0.7487437185929648\n",
      "Validation Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "# XGBoost baseline model\n",
    "xgb = XGBClassifier(random_state=72)\n",
    "xgb.fit(X_train, y_train)\n",
    "print(f\"Training Score: {xgb.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: {xgb.score(X_test, y_test)}\")\n",
    "print(f\"Validation Score: {xgb.score(X_val, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8294413242684008\n",
      "Test Score: 0.7487437185929648\n",
      "Validation Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "# XGBoost baseline model with standard scaler\n",
    "xgb.fit(X_tr_sc, y_train)\n",
    "print(f\"Training Score: {xgb.score(X_tr_sc, y_train)}\")\n",
    "print(f\"Test Score: {xgb.score(X_te_sc, y_test)}\")\n",
    "print(f\"Validation Score: {xgb.score(X_val_sc, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8323972805202483\n",
      "Test Score: 0.7403685092127303\n",
      "Validation Score: 0.9\n"
     ]
    }
   ],
   "source": [
    "# XGBoost forest baseline model with power transformer\n",
    "xgb.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {xgb.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {xgb.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {xgb.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results above, particularly when it comes to validation, it appears that the models perform best overall when the data is run through a power transformer. In addition, the most promising models seem to be Bagging, Gradient Boost and XGBoost. The next step will be to focus on improving these five algorithms with parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for bagging with randomized search\n",
    "params = {\n",
    "    'n_estimators': range(1,100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "         n_estimators=10, n_jobs=None, oob_score=False, random_state=72,\n",
       "         verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=5, n_jobs=None,\n",
       "          param_distributions={'n_estimators': range(1, 100)},\n",
       "          pre_dispatch='2*n_jobs', random_state=72, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a randomized search with 3 folds\n",
    "rs = RandomizedSearchCV(bag, params, 5, cv=3, random_state=72)\n",
    "rs.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 60}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9234407330771505\n",
      "Test Score: 0.7018425460636516\n",
      "Validation Score: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Score the best bagging estimator on training, test, and validation\n",
    "print(f\"Training Score: {rs.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {rs.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {rs.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for bagging with grid search\n",
    "params = {\n",
    "    'n_estimators': range(58,63)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "         n_estimators=10, n_jobs=None, oob_score=False, random_state=72,\n",
       "         verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': range(58, 63)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a grid search with 3 folds\n",
    "gs = GridSearchCV(bag, params, cv=3)\n",
    "gs.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 59}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9234407330771505\n",
      "Test Score: 0.7035175879396985\n",
      "Validation Score: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Score the best bagging estimator on training, test, and validation\n",
    "print(f\"Training Score: {gs.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {gs.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {gs.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best estimator as the final bagging model\n",
    "bag = rs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for adaboost with randomized search\n",
    "params = {\n",
    "    'learning_rate': np.linspace(.001,5,100),\n",
    "    'n_estimators': range(1,100),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=72),\n",
       "          fit_params=None, iid='warn', n_iter=5, n_jobs=None,\n",
       "          param_distributions={'learning_rate': array([1.00000e-03, 5.14949e-02, ..., 4.94951e+00, 5.00000e+00]), 'n_estimators': range(1, 100)},\n",
       "          pre_dispatch='2*n_jobs', random_state=72, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a randomized search with 3 folds\n",
    "rs = RandomizedSearchCV(ada, params, 5, cv=3, random_state=72)\n",
    "rs.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 15, 'learning_rate': 1.465353535353535}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7245048773278155\n",
      "Test Score: 0.7035175879396985\n",
      "Validation Score: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Score the best adaboost estimator on training, test, and validation\n",
    "print(f\"Training Score: {rs.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {gs.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {gs.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for adaboost with grid search\n",
    "params = {\n",
    "    'n_estimators': range(13,18)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=72),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': range(13, 18)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a grid search with 3 folds\n",
    "gs = GridSearchCV(ada, params, cv=3)\n",
    "gs.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 14}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7655926692284954\n",
      "Test Score: 0.7269681742043551\n",
      "Validation Score: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Score the best adaboost estimator on training, test, and validation\n",
    "print(f\"Training Score: {gs.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {gs.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {gs.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best estimator as the final adaboost model\n",
    "ada = rs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for gradient boost with randomized search\n",
    "params = {\n",
    "    'learning_rate': np.linspace(.001,.5,100),\n",
    "    'n_estimators': range(1,200),\n",
    "    'subsample': np.linspace(0,1,100),\n",
    "    'min_samples_split': range(2,10),\n",
    "    'min_samples_leaf': range(1,10),\n",
    "    'max_depth': range(1,50),\n",
    "    'min_impurity_decrease': np.linspace(.001,1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=5, n_jobs=None,\n",
       "          param_distributions={'learning_rate': array([0.001  , 0.00604, ..., 0.49496, 0.5    ]), 'n_estimators': range(1, 200), 'subsample': array([0.    , 0.0101, ..., 0.9899, 1.    ]), 'min_samples_split': range(2, 10), 'min_samples_leaf': range(1, 10), 'max_depth': range(1, 50), 'min_impurity_decrease': a...51, 0.8369 ,\n",
       "       0.85729, 0.87767, 0.89806, 0.91845, 0.93884, 0.95922, 0.97961,\n",
       "       1.     ])},\n",
       "          pre_dispatch='2*n_jobs', random_state=72, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a randomized search with 3 folds\n",
    "rs = RandomizedSearchCV(gb, params, 5, cv=3, random_state=72)\n",
    "rs.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.29292929292929293,\n",
       " 'n_estimators': 131,\n",
       " 'min_samples_split': 4,\n",
       " 'min_samples_leaf': 6,\n",
       " 'min_impurity_decrease': 0.18448979591836737,\n",
       " 'max_depth': 18,\n",
       " 'learning_rate': 0.046363636363636364}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9074785693171741\n",
      "Test Score: 0.7085427135678392\n",
      "Validation Score: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Score the best gradient boost estimator on training, test, and validation\n",
    "print(f\"Training Score: {rs.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {rs.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {rs.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best estimator as the final gradient boost model\n",
    "gb = rs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter distributions for XGBoost with randomized search\n",
    "params = {\n",
    "    'learning_rate': np.linspace(.001,.5,25),\n",
    "    'n_estimators': range(1,200),\n",
    "    'gamma': range(10),\n",
    "    'min_child_weight': range(1,10),\n",
    "    'max_delta_step': range(10),\n",
    "    'subsample': np.linspace(0,1,25),\n",
    "    'colsample_bytree': np.linspace(0,1,25),\n",
    "    'colsample_bylevel': np.linspace(0,1,25),\n",
    "    'colsample_bynode': np.linspace(0,1,25),\n",
    "    'max_depth': range(1,25),\n",
    "    'reg_alpha': range(5),\n",
    "    'reg_lambda': range(5),\n",
    "    'scale_pos_weight': np.linspace(0,1,25),\n",
    "    'base_score': np.linspace(0,1,25)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='multi:softprob', random_state=72, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "          fit_params=None, iid='warn', n_iter=50, n_jobs=None,\n",
       "          param_distributions={'learning_rate': array([0.001  , 0.02179, 0.04258, 0.06338, 0.08417, 0.10496, 0.12575,\n",
       "       0.14654, 0.16733, 0.18812, 0.20892, 0.22971, 0.2505 , 0.27129,\n",
       "       0.29208, 0.31288, 0.33367, 0.35446, 0.37525, 0.39604, 0.41683,\n",
       "       0.43762, 0.45842, 0.47921, 0.5    ]), 'n_esti..., 0.625  , 0.66667, 0.70833, 0.75   , 0.79167, 0.83333,\n",
       "       0.875  , 0.91667, 0.95833, 1.     ])},\n",
       "          pre_dispatch='2*n_jobs', random_state=72, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a randomized search with 3 folds\n",
    "rs = RandomizedSearchCV(xgb, params, 50, cv=3, random_state=72)\n",
    "rs.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.41666666666666663,\n",
       " 'scale_pos_weight': 0.4583333333333333,\n",
       " 'reg_lambda': 0,\n",
       " 'reg_alpha': 2,\n",
       " 'n_estimators': 91,\n",
       " 'min_child_weight': 9,\n",
       " 'max_depth': 15,\n",
       " 'max_delta_step': 3,\n",
       " 'learning_rate': 0.021791666666666668,\n",
       " 'gamma': 0,\n",
       " 'colsample_bytree': 0.6666666666666666,\n",
       " 'colsample_bynode': 0.3333333333333333,\n",
       " 'colsample_bylevel': 1.0,\n",
       " 'base_score': 0.08333333333333333}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best performing parameters\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8016553355010346\n",
      "Test Score: 0.7470686767169179\n",
      "Validation Score: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Score the best XGBoost estimator on training, test, and validation\n",
    "print(f\"Training Score: {rs.best_estimator_.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {rs.best_estimator_.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {rs.best_estimator_.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = rs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a list of estimators for the voting classifier\n",
    "models = [\n",
    "    ('bag', bag),\n",
    "    ('ada', ada),\n",
    "    ('gb', gb),\n",
    "    ('xgb', xgb)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8675731599172333\n",
      "Test Score: 0.7319932998324958\n",
      "Validation Score: 0.93\n"
     ]
    }
   ],
   "source": [
    "vc = VotingClassifier(models)\n",
    "vc.fit(X_tr_pt, y_train)\n",
    "print(f\"Training Score: {vc.score(X_tr_pt, y_train)}\")\n",
    "print(f\"Test Score: {vc.score(X_te_pt, y_test)}\")\n",
    "print(f\"Validation Score: {vc.score(X_val_pt, val['genre'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>duration_ms^3 loudness</th>\n",
       "      <td>0.084715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms^4 loudness</th>\n",
       "      <td>0.061337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy tempo^4</th>\n",
       "      <td>0.047956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy loudness tempo</th>\n",
       "      <td>0.040677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy^3 loudness tempo</th>\n",
       "      <td>0.033887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy loudness^2 tempo</th>\n",
       "      <td>0.030042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy^2 tempo^3</th>\n",
       "      <td>0.021533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loudness tempo^4</th>\n",
       "      <td>0.019903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms tempo</th>\n",
       "      <td>0.018461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms^3 energy loudness</th>\n",
       "      <td>0.016275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy^3 loudness^2</th>\n",
       "      <td>0.014603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms energy^3 loudness</th>\n",
       "      <td>0.012076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms^2 energy loudness tempo</th>\n",
       "      <td>0.011770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms energy^2 loudness tempo</th>\n",
       "      <td>0.011625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy^2 loudness</th>\n",
       "      <td>0.011588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability tempo^4</th>\n",
       "      <td>0.011526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability tempo^3</th>\n",
       "      <td>0.011485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms^2 loudness tempo^2</th>\n",
       "      <td>0.011347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy^2 loudness^2 tempo</th>\n",
       "      <td>0.011005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy^2 loudness tempo</th>\n",
       "      <td>0.010971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms^2 energy^2 loudness</th>\n",
       "      <td>0.010748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability^2 energy^3</th>\n",
       "      <td>0.010017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms energy loudness tempo^2</th>\n",
       "      <td>0.007942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability^3 energy</th>\n",
       "      <td>0.007913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability loudness^4</th>\n",
       "      <td>0.007582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability^4 energy</th>\n",
       "      <td>0.007467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms energy loudness^2 tempo</th>\n",
       "      <td>0.007150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy tempo</th>\n",
       "      <td>0.007094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability energy^2 loudness</th>\n",
       "      <td>0.006616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loudness</th>\n",
       "      <td>0.006493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability^2 duration_ms loudness^2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability duration_ms^4</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability duration_ms^3 energy</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability duration_ms^2 energy^2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability^3 duration_ms energy</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability duration_ms^2 energy tempo</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability duration_ms^2 loudness^2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability duration_ms^2 tempo^2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability duration_ms energy loudness tempo</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability duration_ms energy tempo^2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability duration_ms loudness^3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability^3 duration_ms tempo</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempo^4</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms^3 energy</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms loudness^3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms^3 tempo</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms^2 energy^2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms^2 energy tempo</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms^2 loudness^2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms^2 tempo^2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms energy tempo^2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms loudness^2 tempo</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loudness^2 tempo^2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms tempo^3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy^4</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy^2 loudness^2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy^2 tempo^2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy tempo^3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loudness^4</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempo^5</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "duration_ms^3 loudness                          0.084715\n",
       "duration_ms^4 loudness                          0.061337\n",
       "energy tempo^4                                  0.047956\n",
       "energy loudness tempo                           0.040677\n",
       "energy^3 loudness tempo                         0.033887\n",
       "energy loudness^2 tempo                         0.030042\n",
       "energy^2 tempo^3                                0.021533\n",
       "loudness tempo^4                                0.019903\n",
       "duration_ms tempo                               0.018461\n",
       "duration_ms^3 energy loudness                   0.016275\n",
       "energy^3 loudness^2                             0.014603\n",
       "duration_ms energy^3 loudness                   0.012076\n",
       "duration_ms^2 energy loudness tempo             0.011770\n",
       "duration_ms energy^2 loudness tempo             0.011625\n",
       "energy^2 loudness                               0.011588\n",
       "danceability tempo^4                            0.011526\n",
       "danceability tempo^3                            0.011485\n",
       "duration_ms^2 loudness tempo^2                  0.011347\n",
       "energy^2 loudness^2 tempo                       0.011005\n",
       "energy^2 loudness tempo                         0.010971\n",
       "duration_ms^2 energy^2 loudness                 0.010748\n",
       "danceability^2 energy^3                         0.010017\n",
       "duration_ms energy loudness tempo^2             0.007942\n",
       "danceability^3 energy                           0.007913\n",
       "danceability loudness^4                         0.007582\n",
       "danceability^4 energy                           0.007467\n",
       "duration_ms energy loudness^2 tempo             0.007150\n",
       "energy tempo                                    0.007094\n",
       "danceability energy^2 loudness                  0.006616\n",
       "loudness                                        0.006493\n",
       "...                                                  ...\n",
       "danceability^2 duration_ms loudness^2           0.000000\n",
       "danceability duration_ms^4                      0.000000\n",
       "danceability duration_ms^3 energy               0.000000\n",
       "danceability duration_ms^2 energy^2             0.000000\n",
       "danceability^3 duration_ms energy               0.000000\n",
       "danceability duration_ms^2 energy tempo         0.000000\n",
       "danceability duration_ms^2 loudness^2           0.000000\n",
       "danceability duration_ms^2 tempo^2              0.000000\n",
       "danceability duration_ms energy loudness tempo  0.000000\n",
       "danceability duration_ms energy tempo^2         0.000000\n",
       "danceability duration_ms loudness^3             0.000000\n",
       "danceability^3 duration_ms tempo                0.000000\n",
       "tempo^4                                         0.000000\n",
       "duration_ms^3 energy                            0.000000\n",
       "duration_ms loudness^3                          0.000000\n",
       "duration_ms^3 tempo                             0.000000\n",
       "duration_ms^2 energy^2                          0.000000\n",
       "duration_ms^2 energy tempo                      0.000000\n",
       "duration_ms^2 loudness^2                        0.000000\n",
       "duration_ms^2 tempo^2                           0.000000\n",
       "duration_ms energy tempo^2                      0.000000\n",
       "duration_ms loudness^2 tempo                    0.000000\n",
       "loudness^2 tempo^2                              0.000000\n",
       "duration_ms tempo^3                             0.000000\n",
       "energy^4                                        0.000000\n",
       "energy^2 loudness^2                             0.000000\n",
       "energy^2 tempo^2                                0.000000\n",
       "energy tempo^3                                  0.000000\n",
       "loudness^4                                      0.000000\n",
       "tempo^5                                         0.000000\n",
       "\n",
       "[252 rows x 1 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feat_imp = pd.DataFrame(xgb.feature_importances_, index=poly_feat).sort_values(0, ascending=False)\n",
    "# feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.barh(feat_imp.index, feat_imp[0])\n",
    "# plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb.score(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb.score(X_te_pt, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb.predict(X_val_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_imp = pd.DataFrame(xgb.feature_importances_, index=poly_feat).sort_values(0, ascending=False)\n",
    "# feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.barh(feat_imp.index, feat_imp[0])\n",
    "# plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp_feat = feat_imp[feat_imp[0] > 0.01].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_tr_imp_feat = pd.DataFrame(X_train, columns=poly_feat)[imp_feat]\n",
    "# X_te_imp_feat = pd.DataFrame(X_test, columns=poly_feat)[imp_feat]\n",
    "# X_val_imp_feat = pd.DataFrame(X_val, columns=poly_feat)[imp_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss = StandardScaler()\n",
    "# X_tr_sc = ss.fit_transform(X_tr_imp_feat)\n",
    "# X_te_sc = ss.transform(X_te_imp_feat)\n",
    "# X_val_sc = ss.transform(X_val_imp_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb.fit(X_tr_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb.score(X_tr_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb.score(X_te_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb.predict(X_val_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb.fit(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb.score(X_tr_pt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb.score(X_te_pt, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb.predict(X_val_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb = XGBClassifier(\n",
    "#     max_depth=20,\n",
    "#     learning_rate=.01,\n",
    "#     n_estimators=25,\n",
    "#     objective='multi:softprobs',\n",
    "#     num_class=5,\n",
    "#     gamma=6,\n",
    "#     min_child_weight=3,\n",
    "#     subsample=.75,\n",
    "#     colsample_bytree=.75,\n",
    "#     reg_lambda=1,\n",
    "#     reg_alpha=0,\n",
    "#     seed=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt = DecisionTreeClassifier(max_depth=7, min_samples_split=2, min_samples_leaf=5, random_state=42)\n",
    "# dt.fit(X_tr_sc, y_train)\n",
    "# print(dt.score(X_tr_sc, y_train))\n",
    "# print(dt.score(X_te_sc, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt.predict(X_val_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt = DecisionTreeClassifier(max_depth=7, min_samples_split=2, min_samples_leaf=5, random_state=42)\n",
    "# dt.fit(X_tr_pt, y_train)\n",
    "# print(dt.score(X_tr_pt, y_train))\n",
    "# print(dt.score(X_te_pt, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt.predict(X_val_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn = KNeighborsClassifier(n_neighbors=14, metric='manhattan')\n",
    "# knn.fit(X_tr_sc, y_train)\n",
    "# print(knn.score(X_tr_sc, y_train))\n",
    "# print(knn.score(X_te_sc, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn.predict(X_val_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn = KNeighborsClassifier(n_neighbors=14, metric='manhattan')\n",
    "# knn.fit(X_tr_pt, y_train)\n",
    "# print(knn.score(X_tr_pt, y_train))\n",
    "# print(knn.score(X_te_pt, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn.predict(X_val_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "# lr.fit(X_tr_sc, y_train)\n",
    "# print(lr.score(X_tr_sc, y_train))\n",
    "# print(lr.score(X_te_sc, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr.predict(X_val_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "# lr.fit(X_tr_pt, y_train)\n",
    "# print(lr.score(X_tr_pt, y_train))\n",
    "# print(lr.score(X_te_pt, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr.predict(X_val_pt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
